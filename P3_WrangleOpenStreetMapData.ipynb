{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap Data\n",
    "<small>*This work is done by Adrian Liaw*</small>\n",
    "\n",
    "For this project, I'm going to wrangle the map data of Taipei, my home town.\n",
    "\n",
    "You can doanload the dataset via [MapZen Metro Extracts (Taipei, Taiwan)](https://s3.amazonaws.com/metro-extracts.mapzen.com/taipei_taiwan.osm.bz2)\n",
    "\n",
    "\n",
    "- [Problems Encountered in the Map](#Problems-Encountered-in-the-Map)\n",
    "    - [Storing data with appropriate data structures](#Storing-data-with-appropriate-data-structures)\n",
    "    - [Standardise the names of convenience stores](#Standardise-the-names-of-convenience-stores)\n",
    "    - [Public transportation routes (bus, subway) are unclear](#Public-transportation-routes-are-unclear)\n",
    "- [Overview of the Data](#Overview-of-the-Data)\n",
    "- [Additional Ideas About the Dataset](#Additional-Ideas-About-the-Dataset)\n",
    "    - [Where to open a new convenience store](#Where-to-open-a-new-convenience-store)\n",
    "    - [Additional data exploration using MongoDB queries](#Additional-data-exploration-using-MongoDB-queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are some libraries we're going to use soon\n",
    "\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from pymongo import MongoClient\n",
    "\n",
    "try:\n",
    "    # Speed up a little bit, ujson is written in pure C\n",
    "    import ujson as json\n",
    "except ImportError:\n",
    "    import json\n",
    "\n",
    "# Regular Expression constant\n",
    "PROBLEMCHARS = re.compile(r\"[=\\+/&<>;'\\\"\\?%#$@\\,\\. \\t\\r\\n]\")\n",
    "\n",
    "db = MongoClient(\"localhost\", 27017)[\"map\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered in the Map\n",
    "\n",
    "After exploring the dataset, I think there are three main problems:\n",
    "\n",
    "- Some tags are better stored as other data structures, rather than pure strings like in OSM data.\n",
    "- Standardise the names of convenience stores.\n",
    "- Public transportation routes (bus, subway) are unclear.\n",
    "\n",
    "\n",
    "### Storing data with appropriate data structures\n",
    "Values in the raw OSM XML are all string, but some of them might be better to store as arrays, or sub-document.  \n",
    "For instance, the tag `cuisine` should be stored as array, since a restaurant could serve more than one style of cuisines. In OSM, these values are usually separated by `\",\"` or `\";\"` like `{\"cuisine\": \"Italian;French\"}`.  \n",
    "This also applies to many other tags (like `operators`, some bus routes might be operated by multiple agencies), we can write a generalised function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_into_list(tags, field, delim=\"[,;，、]\"):\n",
    "    \"\"\"Separate the value of some tag into a list (array) instead of storing pure string.\n",
    "\n",
    "    Arguments:\n",
    "    tags -- dict, A dict of tags, {k: v, k: v ...}\n",
    "    field -- str, The tag to separate, e.g. \"cuisine\", \"operator\"\n",
    "\n",
    "    Keyword Arguments:\n",
    "    delim -- str or re object, Seperator for the value, defaults to \"[,;，、]\"\n",
    "             (\"，\" and \"、\" are common separators in our language)\n",
    "\n",
    "    Returns:\n",
    "    dict -- Part of the resulting document. {k: v} if there's nothing to separate; {k: [v1, v2...]} elsewhere.\n",
    "\n",
    "    Modifies:\n",
    "    tags -- Deletes the field.\n",
    "    \"\"\"\n",
    "    delim = re.compile(delim)\n",
    "\n",
    "    if field not in tags: return {}\n",
    "\n",
    "    value = tags.pop(field)\n",
    "\n",
    "    if not delim.search(value): return {field: value}\n",
    "\n",
    "    return {field: [frag.strip() for frag in delim.split(value)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can call it from wherever we want, let's build functions for `operator`, `cuisine`, `ref`, `source`, `phone`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_operator(tags):\n",
    "    \"\"\"\n",
    "    {\"operator\": \"國光客運、大都會客運\"}\n",
    "    Should become:\n",
    "    {\"operator\": [\"國光客運\", \"大都會客運\"]}\n",
    "    \"\"\"\n",
    "    # To fix the ambiguity\n",
    "    if \"Co., Ltd\" in tags.get(\"operator\", \"\"):\n",
    "        return {\"operator\": tags.pop(\"operator\")}\n",
    "    return separate_into_list(tags, \"operator\")\n",
    "\n",
    "def process_cuisine(tags):\n",
    "    \"\"\"\n",
    "    {\"cuisine\": \"Italian; French\"}\n",
    "    Should become:\n",
    "    {\"cuisine\": [\"italian\", \"french\"]}\n",
    "    \"\"\"\n",
    "    if tags.get(\"cuisine\"):\n",
    "        # It should be case-insensitive\n",
    "        tags[\"cuisine\"] = tags[\"cuisine\"].lower()\n",
    "        # I don't know why, but some values looks like this: \"PIZZA_,PASTA\"\n",
    "        return separate_into_list(tags, \"cuisine\", r\"[;，、]|(?:_?,_?)\")\n",
    "    return {}\n",
    "\n",
    "def process_ref(tags):\n",
    "    \"\"\"\n",
    "    Some subway stations have multiple refs, these stations are transfer station.\n",
    "    Other examples like roads, some roads also have multiple refs.\n",
    "    \"\"\"\n",
    "    return separate_into_list(tags, \"ref\")\n",
    "\n",
    "def process_source(tags):\n",
    "    return separate_into_list(tags, \"source\")\n",
    "\n",
    "def process_phone_number(tags):\n",
    "    return separate_into_list(tags, \"phone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>*By the way, these functions with prefix of \"process_\" are going to be called for each element, these functions return partial documents those are fragments of the resulting document. Finally, for each element, we'll create an empty document (dict) initially, then use `update` method to include these fragments.*</small>\n",
    "\n",
    "\n",
    "In the other hand, some tags should be combined, they should resulting to be a sub-document of the main document.  \n",
    "For example: the address. Addresses in OSM are separated into several tags, `addr:street`, `addr:housenumber`, `addr:city`, etc.  \n",
    "Noramlly this type of tags have a key with a colon in it, but not all tags with a colon belong to this type.  \n",
    "Another common case is multilingual tags such as `name`, you can find tons of tags like `name:en`, `name:ja`. They should be combined into an object and stored as `names`, then you can access these values via `names.en`, `names.ja` and so on.\n",
    "\n",
    "Let's again write a general function for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_subdocument(tags, prefix, into):\n",
    "    \"\"\"Combine tags with some prefix into an object, and store as a sub-document (or nested document).\n",
    "\n",
    "    Arguments:\n",
    "    tags -- dict, A dict of tags, {k: v, k: v ...}\n",
    "    prefix -- str, All the tags with a key starting with given prefix are going to merge.\n",
    "    into -- str, A key for the resulting document to store the sub-document.\n",
    "\n",
    "    Returns:\n",
    "    dict -- Part of the resulting document.\n",
    "            Empty dict if no tags matching the prefix; {into: {k (without prefix): v, k: v ...}} otherwise.\n",
    "\n",
    "    Modifies:\n",
    "    tags -- Deletes the field.\n",
    "    \"\"\"\n",
    "    document = defaultdict(lambda: {})\n",
    "    for k in list(tags):\n",
    "        if k.startswith(prefix):\n",
    "            document[into][k[len(prefix):]] = tags.pop(k)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, use it to construct other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_address(tags):\n",
    "    \"\"\"\n",
    "    {\"addr:full\": \"11656臺北市文山區新光路二段32號\",\n",
    "     \"addr:country\": \"TW\",\n",
    "     \"addr:housenumber\": \"32\"}\n",
    "\n",
    "    Should become:\n",
    "\n",
    "    {\"address\": {\n",
    "        \"full\": \"11656臺北市文山區新光路二段32號\",\n",
    "        \"country\": \"TW\",\n",
    "        \"housenumber\": \"32\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    # address field should be addr:full\n",
    "    if tags.get(\"address\"):\n",
    "        tags[\"addr:full\"] = tags.pop(\"address\")\n",
    "    return as_subdocument(tags, \"addr:\", \"address\")\n",
    "\n",
    "def process_names(tags):\n",
    "    \"\"\"\n",
    "    {\"name:zh\": \"新店區\",\n",
    "     \"name:en\": \"Xindian District\",\n",
    "     \"name:ja\": \"新店区\"}\n",
    "\n",
    "    Should become:\n",
    "\n",
    "    {\"names\": {\n",
    "        \"zh\": \"新店區\",\n",
    "        \"en\": \"Xindian District\",\n",
    "        \"ja\": \"新店区\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return as_subdocument(tags, \"name:\", \"names\")\n",
    "\n",
    "def process_alt_names(tags):\n",
    "    return as_subdocument(tags, \"alt_name:\", \"alt_names\")\n",
    "\n",
    "def process_old_names(tags):\n",
    "    return as_subdocument(tags, \"old_name:\", \"old_names\")\n",
    "\n",
    "def process_official_names(tags):\n",
    "    return as_subdocument(tags, \"official_name:\", \"official_names\")\n",
    "\n",
    "def process_refs(tags):\n",
    "    # This is also about multilingual\n",
    "    return as_subdocument(tags, \"ref:\", \"refs\")\n",
    "\n",
    "def process_GNS(tags):\n",
    "    return as_subdocument(tags, \"GNS:\", \"GNS\")\n",
    "\n",
    "def process_building_props(tags):\n",
    "    # building:levels building:height etc.\n",
    "    return as_subdocument(tags, \"building:\", \"building_props\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardise the names of convenience stores\n",
    "Well, this is a very localised problem. This is important for Taiwanese because convenience stores are [a part of our lives](https://en.wikipedia.org/wiki/Convenience_store#Taiwan), we can do a lot of things there. They are everywhere in Taiwan, and I really mean, EVERYWHERE.\n",
    "\n",
    "There are four main convenience store companies in Taiwan: 7-Eleven, Family Mart, Hi-Life and OK Mart. When we talk about convenience stores, we always mean these four, not others.\n",
    "\n",
    "So I had this idea of labeling these convenience stores correctly in our data, this may be helpful if we're going to do some analysis about convenience stores. Now the problem here is that these stores have varying names, since the data were edited by lots of different users. For instance, 7-Eleven, some people wrote 7-ELEVEn, 7-11, Seven-Eleven.\n",
    "\n",
    "Also, there're many nodes were labelled as `{\"shop\": \"convenience\"}`, but many of them are not what we \"expect\".\n",
    "Our task here is to label those four companies' stores as a stand-alone group, and also label with the unified company name or brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_conv_stores(tags):\n",
    "    \"\"\"Identify the convenience store company based on the name, and clean it.\n",
    "\n",
    "    {\"shop\": \"convenience\",\n",
    "     \"name\": \"7 eleven\"}\n",
    "\n",
    "    Should become:\n",
    "\n",
    "    {\"shop\": \"convenience_store\",\n",
    "     \"brand\": \"7-Eleven\"}\n",
    "    \"\"\"\n",
    "    if tags.get(\"shop\") != \"convenience\" or tags.get(\"name\") == None:\n",
    "        return {}\n",
    "\n",
    "    name = tags[\"name\"].lower()\n",
    "\n",
    "    # 7 Eleven, seven-eleven, 7-11, 統一超商(company's legal name in our language, but we never say this)\n",
    "    if ((\"7\" in name or \"seven\" in name) and (\"11\" in name or \"eleven\" in name)) or \"統一\" in name:\n",
    "        output = {\"shop\": \"convenience_store\", \"brand\": \"7-Eleven\"}\n",
    "\n",
    "    # Family Mart, FamilyMart, Family-Mart, 全家便利商店, 全家(for short, we always say this)\n",
    "    elif (\"family\" in name and \"mart\" in name) or \"全家\" in name:\n",
    "        output = {\"shop\": \"convenience_store\", \"brand\": \"FamilyMart\"}\n",
    "\n",
    "    # Hi-Life, HiLife, hi life, 萊爾富(again, we say this)\n",
    "    elif (\"hi\" in name and \"life\" in name) or \"萊爾富\" in name:\n",
    "        output = {\"shop\": \"convenience_store\", \"brand\": \"Hi-Life\"}\n",
    "\n",
    "    # OK, ok mart, OK‧MART\n",
    "    elif \"ok\" in name:\n",
    "        output = {\"shop\": \"convenience_store\", \"brand\": \"OK·MART\"}\n",
    "\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "    del tags[\"shop\"]\n",
    "    if \"brand\" in tags: del tags[\"brand\"]\n",
    "    # We're not going to drop \"name\", keep it to the end\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public transportation routes are unclear\n",
    "\n",
    "As a heavy public transportation user, I take buses and MRT (Taipei Metro Rapid Transit) everyday. It's a good idea to include public transit information in the further analysis.\n",
    "\n",
    "These route data are stored as relations in OSM XML, I'm going to separate each route relation into three parts, stops, depots and path, where stops are bus stops or MRT stations (nodes), depots are those bus depots and MRT depots (closed ways / area ways), path is an array of open ways.\n",
    "\n",
    "In this `process_route` function, I'm going to have an element as the argument, because we need `<member>`s under `<relation>`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_route(element):\n",
    "    \"\"\"Break a route relation into an object of three parts\n",
    "\n",
    "    Argument:\n",
    "    element: <relation></relation>\n",
    "\n",
    "    Returns:\n",
    "    dict -- Part of the resulting document, containing \"route_content\", which contains \"stops\", \"depots\" and \"path\".\n",
    "    \"\"\"\n",
    "    document = {\"route_content\": defaultdict(lambda: [])}\n",
    "\n",
    "    for member in element.getiterator(\"member\"):\n",
    "\n",
    "        # After a bit of exploring, I found out they don't have much difference\n",
    "        if member.get(\"role\").lower() in [\"stop\", \"backward_stop\", \"forward_stop\", \"platform\"]:\n",
    "            document[\"route_content\"][\"stops\"].append(member.get(\"ref\"))\n",
    "\n",
    "        elif member.get(\"role\") == \"depot\":\n",
    "            document[\"route_content\"][\"depots\"].append(member.get(\"ref\"))\n",
    "\n",
    "        else:\n",
    "            document[\"route_content\"][\"path\"].append(member.get(\"ref\"))\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another type of relation I tried to deal with is boundary,  \n",
    "This will be useful if we want to analyse based on administrative areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_boundary(element):\n",
    "    \"\"\"Break a boundary relation into an object of three parts\n",
    "\n",
    "    Argument:\n",
    "    element: <relation></relation>\n",
    "\n",
    "    Returns:\n",
    "    dict -- Part of the resulting document, containing \"boundary_data\",\n",
    "            which contains \"admin_centre\"(or \"label\"), \"boundary\", \"subarea\"\n",
    "    \"\"\"\n",
    "    document = {\"boundary_data\": defaultdict(lambda: [])}\n",
    "\n",
    "    for member in element.getiterator(\"member\"):\n",
    "\n",
    "        if member.get(\"role\") in [\"admin_centre\", \"label\"]:\n",
    "            document[\"boundary_data\"][member.get(\"role\")] = member.get(\"ref\")\n",
    "\n",
    "        elif member.get(\"role\") in [\"outer\", \"inner\"]:\n",
    "            # Cities like New Taipei City have a ring-like boundary, should include \"outer\" or \"inner\"\n",
    "            document[\"boundary_data\"][\"boundary\"].append(\n",
    "                {\"type\": member.get(\"role\"), \"ref\": member.get(\"ref\")}\n",
    "            )\n",
    "\n",
    "        elif member.get(\"role\") == \"subarea\":\n",
    "            document[\"boundary_data\"][\"subareas\"].append(member.get(\"ref\"))\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are what I've solved in the auditing phase, let's wrap it up and import them into database.\n",
    "\n",
    "This is how the final `shape_element` function looks like, some additional functions will be defined right after this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_element(element):\n",
    "    \"\"\"Shape the element into dictionary like this:\n",
    "    {\n",
    "        \"id\": \"2085444960\",\n",
    "        \"element\": \"node\",\n",
    "        \"loc\": [121.524852, 25.0265463],\n",
    "        \"name\": \"混_hun\",\n",
    "        \"created\": {\n",
    "            \"uid\": \"23731\",\n",
    "            \"version\": \"2\",\n",
    "            \"user\": \"Imrehg\",\n",
    "            \"changeset\": \"18946405\",\n",
    "            \"timestamp\": {\"$date\": \"2013-11-17T03:54:33Z\"}\n",
    "        },\n",
    "        \"address\": {\n",
    "            \"street\": \"和平東路一段104巷\",\n",
    "            \"housenumber\": \"6\"\n",
    "        },\n",
    "        \"amenity\": \"cafe\",\n",
    "        \"website\": \"http://huncoworkingspace.blogspot.tw/\",\n",
    "        \"wifi\": \"free\",\n",
    "        \"internet_access\": \"wlan\",\n",
    "        \"cuisine\": \"coffee_shop\",\n",
    "    }\n",
    "    \"\"\"\n",
    "    if elem.tag in [\"node\", \"way\", \"relation\"]:\n",
    "        document = {}\n",
    "        # process_element_meta deals with attributes of the element\n",
    "        document.update(process_element_meta(elem))\n",
    "        # process_tags runs through the tags auditing functions like process_address, process_conv_stores\n",
    "        document.update(process_tags(elem))\n",
    "\n",
    "        if elem.tag == \"way\":\n",
    "            # process_nds grabs nodes (<nd>) in a way element into \"node_refs\"\n",
    "            document.update(process_nds(elem))\n",
    "\n",
    "        if elem.tag == \"relation\":\n",
    "            # Two special relations, route and boundary\n",
    "            if document.get(\"route\") in [\"bus\", \"subway\", \"railway\"]:\n",
    "                document.update(process_route(elem))\n",
    "\n",
    "            elif document.get(\"boundary\") == \"administrative\":\n",
    "                document.update(process_boundary(elem))\n",
    "\n",
    "            else:\n",
    "                # Otherwise, do a generalised transformation\n",
    "                document.update(process_relation(elem))\n",
    "\n",
    "        return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_element_meta(element):\n",
    "    \"\"\"Extracts xml attributes from the element, and turn it into an appropriate form\n",
    "\n",
    "    Argument:\n",
    "    element: An XML element, could be node, way, or relation\n",
    "\n",
    "    Returns:\n",
    "    dict -- Part of the resulting document, including the element's metadata\n",
    "    \"\"\"\n",
    "    document = {\"element\": element.tag, \"created\": {}}\n",
    "\n",
    "    for key, val in element.attrib.items():\n",
    "\n",
    "        if key not in [\"lon\", \"lat\", \"timestamp\", \"id\"]:\n",
    "            document[\"created\"][key] = val\n",
    "\n",
    "        elif key == \"timestamp\":\n",
    "            # Found out that we can use MongoDB's Extended JSON format to store something as Date if we use mongoimport\n",
    "            document[\"created\"][\"timestamp\"] = {\"$date\": element.get(\"timestamp\")}\n",
    "\n",
    "        elif key == \"id\":\n",
    "            document[\"id\"] = element.get(\"id\")\n",
    "\n",
    "    if element.tag == \"node\":\n",
    "        # Can get benefits of 2d indexes and geospatial queries\n",
    "        document[\"loc\"] = [float(element.get(\"lon\")), float(element.get(\"lat\"))]\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_tags(element):\n",
    "    \"\"\"Get all tags and feed them to process functions we just wrote\n",
    "\n",
    "    Argument:\n",
    "    element: An XML element, could be node, way, or relation\n",
    "\n",
    "    Returns:\n",
    "    dict -- Part of the resulting document, including the element's tags\n",
    "    \"\"\"\n",
    "    # Get all the tags into a dictionary\n",
    "    tags = {}\n",
    "    for tag in element.getiterator(\"tag\"):\n",
    "        if PROBLEMCHARS.search(tag.get(\"k\")):\n",
    "            # Found out all the keys with problematic characters\n",
    "            # are just placed by dots where it should be a colon\n",
    "            if \".\" in tag.get(\"k\"):\n",
    "                tag.set(\"k\", tag.get(\"k\").replace(\".\", \":\"))\n",
    "            else:\n",
    "                continue\n",
    "        tags[tag.get(\"k\")] = tag.get(\"v\")\n",
    "\n",
    "    document = {}\n",
    "    for processor in [process_operator,\n",
    "                      process_cuisine,\n",
    "                      process_ref,\n",
    "                      process_source,\n",
    "                      process_phone_number,\n",
    "                      process_address,\n",
    "                      process_names,\n",
    "                      process_alt_names,\n",
    "                      process_old_names,\n",
    "                      process_official_names,\n",
    "                      process_refs,\n",
    "                      process_GNS,\n",
    "                      process_building_props,\n",
    "                      process_conv_stores]:\n",
    "        document.update(processor(tags))\n",
    "\n",
    "    # Remaining tags should be added as normal fields, like in Lesson 6\n",
    "    document.update(tags)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_nds(element):\n",
    "    \"\"\"\n",
    "    <way ...>\n",
    "        <nd ref=\"12345678\">\n",
    "        <nd ref=\"90123456\">\n",
    "    </way>\n",
    "\n",
    "    Should become:\n",
    "\n",
    "    {...\n",
    "     \"node_refs\": [\"12345678\", \"90123456\"]}\n",
    "    \"\"\"\n",
    "    document = {\"node_refs\": []}\n",
    "    for nd in element.getiterator(\"nd\"):\n",
    "        document[\"node_refs\"].append(nd.get(\"ref\"))\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_relation(element):\n",
    "    \"\"\"\n",
    "    <relation ...>\n",
    "        <member type=\"node\" role=\"foo\" ref=\"12345678\">\n",
    "        <member type=\"way\" role=\"\" ref=\"90123456\">\n",
    "    </relation>\n",
    "\n",
    "    Should become:\n",
    "\n",
    "    {...\n",
    "     \"members\": [\n",
    "        {\"type\": \"node\",\n",
    "         \"role\": \"foo\",\n",
    "         \"ref\": \"12345678\"},\n",
    "        {\"type\": \"way\",\n",
    "         \"role\": \"\",\n",
    "         \"ref\": \"90123456\"}\n",
    "     ]}\n",
    "    \"\"\"\n",
    "    document = {\"members\": []}\n",
    "    for member in element.getiterator(\"member\"):\n",
    "        document[\"members\"].append(member.attrib)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final step, dump them into a file then import them into MongoDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-17T11:25:23.696+0800\tconnected to: localhost\n",
      "2016-01-17T11:25:26.687+0800\t[###.....................] map.taipei\t22.4 MB/140.8 MB (15.9%)\n",
      "2016-01-17T11:25:29.689+0800\t[#######.................] map.taipei\t43.5 MB/140.8 MB (30.9%)\n",
      "2016-01-17T11:25:32.692+0800\t[###########.............] map.taipei\t64.7 MB/140.8 MB (45.9%)\n",
      "2016-01-17T11:25:35.687+0800\t[##############..........] map.taipei\t86.8 MB/140.8 MB (61.6%)\n",
      "2016-01-17T11:25:38.687+0800\t[#################.......] map.taipei\t105.4 MB/140.8 MB (74.8%)\n",
      "2016-01-17T11:25:41.687+0800\t[#####################...] map.taipei\t128.2 MB/140.8 MB (91.0%)\n",
      "2016-01-17T11:25:42.905+0800\t[########################] map.taipei\t140.8 MB/140.8 MB (100.0%)\n",
      "2016-01-17T11:25:42.905+0800\timported 664962 documents\n"
     ]
    }
   ],
   "source": [
    "with open(\"taipei_taiwan.osm.json\", \"w\") as output:\n",
    "    for _, elem in ET.iterparse(\"taipei_taiwan.osm\"):\n",
    "        document = shape_element(elem)\n",
    "        if document:\n",
    "            json.dump(document, output)\n",
    "\n",
    "!mongoimport -d map -c taipei taipei_taiwan.osm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Data\n",
    "\n",
    "File sizes:  \n",
    "`taipei_taiwan.osm ........ 128 MB`  \n",
    "`taipei_taiwan.osm.json ... 141 MB`  \n",
    "\n",
    "Number of documents: `664962`  \n",
    "(Actually you can see it in the output cell of `In[14]`)\n",
    "\n",
    "\n",
    "Number of nodes, ways, relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'node', 'count': 583636},\n",
       " {'_id': 'way', 'count': 76940},\n",
       " {'_id': 'relation', 'count': 4386}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.taipei.aggregate([\n",
    "    {\"$group\": {\"_id\": \"$element\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$sort\": {\"count\": -1}},\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of MRT stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.taipei.find({\"station\": \"subway\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of bus stops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.taipei.find({\"highway\": \"bus_stop\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenience stores count for each company:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '7-Eleven', 'count': 751},\n",
       " {'_id': 'FamilyMart', 'count': 541},\n",
       " {'_id': 'Hi-Life', 'count': 175},\n",
       " {'_id': 'OK·MART', 'count': 97}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.taipei.aggregate([\n",
    "    {\"$match\": {\"shop\": \"convenience_store\"}},\n",
    "    {\"$group\": {\"_id\": \"$brand\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$sort\": {\"count\": -1}},\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas About the Dataset\n",
    "\n",
    "### Where to open a new convenience store\n",
    "As I said, convenience stores plays an important role in our lives, and it's important for a convenience store company to decide which place is good to open a new store. If some place has a considerable amount of people pass by or stay, and there's no such convenience store, and it's definitely a great place.\n",
    "\n",
    "Now, our dataset have some amenities data, then we can infer about whether or not there will be an opportunity to have many customers coming. Places like schools, MRT stations or bus stops with many routes passing through may have large amount of people.  \n",
    "\n",
    "The benefit of using our data is, we have all sorts of data like restaurants, schools, hospitals, bus stops, not only just convenience stores, and we can infer something from multiple perspectives.  \n",
    "However, a challenge we may encounter is how to measure the importance of some place, because they should be weighted. Another problem is the distance, distances should be calculated based on streets, roads, how people would walk, not direct distance of two points.\n",
    "\n",
    "### Additional data exploration using MongoDB queries\n",
    "\n",
    "Density of convenience stores, stores/km2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4923664122137406"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The area we selected about 1048 square kilometres\n",
    "db.taipei.find({\"shop\": \"convenience_store\"}).count() / 1048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 3 nearest convenience stores from an MRT station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'address': {'housenumber': '119', 'street': '北新路二段'},\n",
       "  'brand': 'FamilyMart',\n",
       "  'distance': 0.0002057793235521875,\n",
       "  'id': '1770221125',\n",
       "  'loc': [121.5427351, 24.9749324]},\n",
       " {'brand': 'FamilyMart',\n",
       "  'distance': 0.0002065491708936941,\n",
       "  'id': '1983147356',\n",
       "  'loc': [121.5431203, 24.9750737]},\n",
       " {'address': {'housenumber': '8', 'street': '北新路二段97巷'},\n",
       "  'brand': 'OK·MART',\n",
       "  'distance': 0.0008875231884306044,\n",
       "  'id': '3881721569',\n",
       "  'loc': [121.5422982, 24.9743891]}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Must create a 2d index before we use geospatial queries\n",
    "db.taipei.create_index([(\"loc\", \"2d\")])\n",
    "\n",
    "list(db.taipei.aggregate([\n",
    "    {\"$geoNear\": {\n",
    "        \"near\": db.taipei.find_one({\"station\": \"subway\", \"name\": \"七張\"})[\"loc\"],\n",
    "        \"query\": {\"shop\": \"convenience_store\"},\n",
    "        \"distanceField\": \"distance\",\n",
    "        \"num\": 3\n",
    "    }},\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"id\": 1,\n",
    "        \"brand\": 1,\n",
    "        \"distance\": 1,\n",
    "        \"loc\": 1,\n",
    "        \"address\": 1\n",
    "    }}\n",
    "]))\n",
    "\n",
    "# For this station (七張), there's a FamilyMart right beside the entrance, and another one across the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 bus stops passed by most routes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '2315915814', 'count': 37, 'name': '師大分部'},\n",
       " {'_id': '2307668493', 'count': 35, 'name': '師大分部'},\n",
       " {'_id': '1708079078', 'count': 35, 'name': '捷運公館站'},\n",
       " {'_id': '2063258381', 'count': 34, 'name': '捷運公館站'},\n",
       " {'_id': '1956926633', 'count': 29, 'name': '檳榔路'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.taipei.aggregate([\n",
    "    {\"$match\": {\"route\": \"bus\"}},\n",
    "    {\"$unwind\": \"$route_content.stops\"},\n",
    "    {\"$group\": {\"_id\": \"$route_content.stops\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$sort\": {\"count\": -1}},\n",
    "    {\"$limit\": 5},\n",
    "    {\"$lookup\": {\"from\": \"taipei\",\n",
    "                 \"localField\": \"_id\",\n",
    "                 \"foreignField\": \"id\",\n",
    "                 \"as\": \"stop\"}},\n",
    "    {\"$unwind\": \"$stop\"},\n",
    "    {\"$project\": {\"_id\": \"$stop.id\",\n",
    "                  \"name\": \"$stop.name\",\n",
    "                  \"count\": 1}}\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Well, after this exploring and wrangling, I'm sure there're whole bunch of data missing in Taipei area, but I can see those activities on OpenStreetMap, the local community of OpenStreetMap in Taiwan is pretty active. I actually pretty like this project, and I've spent a lot of time on this, it's fun and interesting, and I'm always trying to dig deeper and deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<small>\n",
    "Resources referred/used:\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Convenience_store\n",
    "- https://en.wikipedia.org/wiki/7-Eleven\n",
    "- https://zh.wikipedia.org/wiki/%E5%8F%B0%E7%81%A3%E4%BE%BF%E5%88%A9%E5%95%86%E5%BA%97%E5%88%97%E8%A1%A8\n",
    "- http://www.5284.com.tw/Dybus.aspx\n",
    "- https://en.wikipedia.org/wiki/Taipei_Joint_Bus_System\n",
    "- https://en.wikipedia.org/wiki/Taipei_Metro\n",
    "- http://stackoverflow.com/questions/22890082/convert-to-date-mongodb-via-mongoimport\n",
    "- https://docs.mongodb.org/v3.0/reference/operator/aggregation/geoNear/\n",
    "</small>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
